# ü§ñ Reinforcement Learning Projects (CartPole & Pirate Maze)  
*Algorithms & Data Structures Artifact ‚Äì CS-499 Capstone*

---

## üìñ Project Overview
This artifact was originally developed in **CS-370: Emerging Trends in Computer Science** and enhanced during the **CS-499 Capstone**. It demonstrates the implementation of **Reinforcement Learning (RL)** using **Deep Q-Learning (DQL)** to train an intelligent agent capable of navigating an environment, maximizing rewards, and avoiding penalties.

The primary artifact is a Jupyter Notebook (`TreasureHuntGame.ipynb`) that implements Deep Q-Learning. Supporting Python modules include:
- `TreasureEnvironment.py` ‚Äì Defines the 8√ó8 grid world and reward logic  
- `GameExperience.py` ‚Äì Manages experience replay and state-action memory for training  

This project showcases how machine learning algorithms can be applied to solve complex decision-making problems through iterative learning and reward feedback.

---

## üéØ Why I Selected This Artifact
I selected this artifact because it represents my growth in **algorithmic thinking and AI-based problem solving**. It demonstrates my ability to:
- Design and implement learning algorithms using neural networks  
- Apply algorithmic principles such as **exploration vs. exploitation**  
- Optimize performance through hyperparameter tuning and policy evaluation  
- Translate abstract theory into functional, executable code  

This project goes beyond traditional sorting or search algorithms and demonstrates applied intelligence through computational learning.

---

## ‚öôÔ∏è Capstone Enhancements (CS-499)
During the capstone, I improved the original project to enhance performance, clarity, and educational value:

- **Refined the Q-Learning training loop** for stability and faster convergence  
- Added **reward tracking and visualization** to monitor learning progress  
- Introduced **epsilon-decay strategies** to balance exploration and exploitation  
- Enhanced documentation to explain algorithm design trade-offs and edge cases  
- Improved code structure with modular functions and annotated logic  

---

## üß† Skills and Growth Demonstrated
This artifact strengthened my skills in:

- **Algorithm Design:** Implementing reinforcement learning from first principles  
- **Data Structures:** Managing replay memory and Q-value tables  
- **Machine Learning Logic:** Using neural networks to approximate state-action values  
- **Iterative Problem Solving:** Optimizing models through experimentation, tuning, and evaluation  

I gained a deeper appreciation for how AI agents learn dynamically without explicit instructions ‚Äî a core challenge in modern computational systems.

---

## üéì Course Outcome Alignment
This artifact supports key CS-499 learning outcomes:

- **CO3 ‚Äì Algorithmic Problem Solving:** Designed and optimized RL algorithms using state-action rewards  
- **CO4 ‚Äì Use of Tools & Techniques:** Applied Python, NumPy, and neural methods to build an intelligent agent  
- **CO2 ‚Äì Communication:** Documented and visualized performance trends for technical interpretation  

---

## üîó Resources
- **Source Code Repository:** [GitHub ‚Äì Treasure Hunt RL Agent](https://github.com/niazkhan0731/niazkhan0731.github.io/tree/main/artifacts/treasure-hunt)  
- **Return to Portfolio Home Page:** [Back to Home](../../index.md)

---

¬© 2025 **Niaz Khan**  
Southern New Hampshire University ‚Äì Computer Science Capstone
